{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-163aa6b4eb3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpython_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "import transformers as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (4.36.1)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.94-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (2.22.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2020.10.28-cp37-cp37m-win_amd64.whl (272 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (1.16.5)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from transformers==3.0.2) (3.0.12)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.43.tar.gz (883 kB)\n",
      "Requirement already satisfied: six in c:\\users\\sonwang.redmond\\appdata\\roaming\\python\\python37\\site-packages (from packaging->transformers==3.0.2) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from packaging->transformers==3.0.2) (2.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: click in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from sacremoses->transformers==3.0.2) (0.13.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893260 sha256=d526e71dab1f53a0584012d44f8c082dd7e9807b974d05bc0daf3b4ca9153919\n",
      "  Stored in directory: c:\\users\\sonwang.redmond\\appdata\\local\\pip\\cache\\wheels\\69\\09\\d1\\bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, regex, tokenizers, sacremoses, transformers\n",
      "Successfully installed regex-2020.10.28 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\sonwang.redmond\\appdata\\local\\continuum\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6776, 0.6531, 0.0457, 0.9424],\n",
       "         [0.4925, 0.9985, 0.7585, 0.0317],\n",
       "         [0.2769, 0.9590, 0.0498, 0.1786]]),\n",
       " tensor([[0.4095, 0.5523, 0.9228, 0.0484],\n",
       "         [0.8004, 0.3307, 0.5326, 0.2070],\n",
       "         [0.2271, 0.8472, 0.7639, 0.7220]]),\n",
       " tensor([[0.6776, 0.6531, 0.0457, 0.9424, 0.4095, 0.5523, 0.9228, 0.0484],\n",
       "         [0.4925, 0.9985, 0.7585, 0.0317, 0.8004, 0.3307, 0.5326, 0.2070],\n",
       "         [0.2769, 0.9590, 0.0498, 0.1786, 0.2271, 0.8472, 0.7639, 0.7220]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(999)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "x2 = torch.rand(3,4)\n",
    "y = torch.cat((x1, x2), dim =1)\n",
    "x1,x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'agents',\n",
       " '##tar',\n",
       " '##t',\n",
       " ']',\n",
       " 'hello',\n",
       " '[',\n",
       " 'x',\n",
       " '_',\n",
       " 'sep',\n",
       " ']',\n",
       " 'songs',\n",
       " '##ong']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers as tf\n",
    "tf.__version__\n",
    "#'3.0.2'\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "len(tokenizer)                                                                                                                                                                                                                                                                                                                                                                                                           #30522\n",
    "x = '[AGENTSTART] hello [X_SEP] songsong'  \n",
    "tokenizer.tokenize(x) \n",
    "#['[', 'agents', '##tar', '##t', ']', 'hello', '[', 'x', '_', 'sep', ']', 'songs', '##ong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[agentstart]', 'hello', '[x_sep]', 'songs', '##ong']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_added_toks = tokenizer.add_tokens(['[AGENTSTART]','[X_SEP]']) \n",
    "tokenizer.tokenize(x) \n",
    "#['[agentstart]', 'hello', '[x_sep]', 'songs', '##ong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[AGENTSTART]', 'hello', '[X_SEP]', 'songs', '##ong']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')                                                                                                                                                                                                                                                                                        \n",
    "num_added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[AGENTSTART]','[X_SEP]']}                        )                                                                                                                                                                                                                                                                                                                                                      \n",
    "tokenizer.tokenize(x)                                                                                                                                                                                                                                                                                                                                                                                                    \n",
    "#['[AGENTSTART]', 'hello', '[X_SEP]', 'songs', '##ong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'cute', 'dog']\n",
      "[2023, 2003, 1037, 10140, 3899]\n",
      "CPU times: user 93.8 ms, sys: 46.9 ms, total: 141 ms\n",
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = 'This is a cute dog' \n",
    "    \n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "tokens = bert_tokenizer.tokenize(text)\n",
    "text_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tokens)\n",
    "print(text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f18b0fe3278456a862ff3463affecd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=898823, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463ceb1e5a8a40dcbc9d66d9cbda4107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['This', 'Ġis', 'Ġa', 'Ġcute', 'Ġdog']\n",
      "[713, 16, 10, 11962, 2335]\n",
      "CPU times: user 500 ms, sys: 281 ms, total: 781 ms\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = 'This is a cute dog'\n",
    "roberta_tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')  \n",
    "tokens = roberta_tokenizer.tokenize(text)\n",
    "text_ids = roberta_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tokens)\n",
    "print(text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'Ġis', 'Ġa', 'Ġcute', 'Ġdog'], ['This', 'Ġis', 'Ġa', 'Ġcute', 'Ġcat', 'Ġbut', 'ĠI', 'Ġdont', 'Ġlike', 'Ġcat', '!']]\n",
      "[[713, 16, 10, 11962, 2335], [713, 16, 10, 11962, 4758, 53, 38, 33976, 101, 4758, 328]]\n"
     ]
    }
   ],
   "source": [
    "text = ['This is a cute dog', 'This is a cute cat but I dont like cat!'] \n",
    "tokens = [roberta_tokenizer.tokenize(x) for x in text]\n",
    "text_ids = [roberta_tokenizer.convert_tokens_to_ids(tk) for tk in tokens]\n",
    "print(tokens)\n",
    "print(text_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  713,    16,    10, 11962,  2335])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x = torch.tensor(text_ids[0], dtype=torch.long)\n",
    "tensor_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  713,    16,    10, 11962,  4758,    53,    38, 33976,   101,  4758,\n",
       "          328])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(text_ids[1], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 400)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Numerator:\n",
    "    def __init__(self, nums):\n",
    "        self.nums = nums\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.nums)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.nums[i]\n",
    "    \n",
    "x = Numerator([x for x in range(0, 1000, 100)])\n",
    "x[3], x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<mask>', '<pad>')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer.mask_token, roberta_tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
